{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15c5d28e-8a59-4357-8cbe-334381189235",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    " https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97fad78b-bd57-43d7-a0c6-75beedbabce1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "filepath = '/Volumes/sample_catalog/sample_schema/sample_volume/SMSSpamCollection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e22f287b-6f3a-4acf-92ed-383d8516ad6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.text(filepath)\n",
    "pdf = df.toPandas()\n",
    "pdf[['label', 'message']] = pdf['value'].str.split('\\t', expand=True)\n",
    "pdf = pdf.drop(columns='value')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "529b6add-64a0-4938-b4f7-69f39b03e27e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5263827-0c93-473a-982a-a60a5992ed7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(pdf['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1f76d5f-133f-40c6-b38f-87a0e33b155e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The dataset is imbalanced: many more \"ham\" messages than \"spam\".\n",
    "\n",
    "Imbalance causes models to favor the majority class, which leads to high accuracy but poor detection of \"spam\" (low recall)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21fd2719-978f-47ee-b673-fedc083a09d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "import pandas as pd\n",
    "\n",
    "# Separate classes\n",
    "spam_df = pdf[pdf['label'] == 'spam']\n",
    "ham_df = pdf[pdf['label'] == 'ham']\n",
    "\n",
    "# Upsample spam to match ham\n",
    "spam_upsampled = resample(spam_df, \n",
    "                          replace=True,     # sample with replacement\n",
    "                          n_samples=len(ham_df), \n",
    "                          random_state=42)\n",
    "\n",
    "# Combine into balanced dataset\n",
    "balanced_df = pd.concat([ham_df, spam_upsampled])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c533e3da-a46d-4073-805a-3eda65748e2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(balanced_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b4d060b-83c3-4f89-a0e8-bb21f5d9e709",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    balanced_df['message'], balanced_df['label'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a775a85-cbf9-45c7-a61a-b8e10fdee2db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# vectorizer = TfidfVectorizer(stop_words='english')\n",
    "# X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "# X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Custom tokenizer to extract only words with 3 or more English letters\n",
    "def clean_tokenizer(text):\n",
    "    return re.findall(r'\\b[a-z]{3,}\\b', text.lower())\n",
    "\n",
    "# Rebuild vectorizer with clean tokenizer\n",
    "vectorizer = TfidfVectorizer(tokenizer=clean_tokenizer, stop_words='english')\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72be09ca-8755-4d51-8177-1a65c0058df9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "ML models can't work directly with text.\n",
    "\n",
    "We use TF-IDF (Term Frequency–Inverse Document Frequency):\n",
    "\n",
    "Tells us which words are important to each message.\n",
    "\n",
    "Converts messages into numerical vectors (feature matrix).\n",
    "\n",
    "TF-IDF stands for:\n",
    "TF = Term Frequency:\n",
    "How frequently a word appears in a message.\n",
    "\n",
    "IDF = Inverse Document Frequency:\n",
    "How rare that word is across all messages.\n",
    "\n",
    "Together, TF-IDF captures:\n",
    "\n",
    "\"How important is a word in this message, compared to the whole dataset?\"\n",
    "\n",
    "Why stop_words='english'?\n",
    "This removes common words like:\n",
    "\n",
    "\"the\", \"is\", \"and\", \"a\", \"you\", etc.\n",
    "\n",
    "These don’t help the model learn much — they appear in both spam and ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e11bbbb-93ab-45b6-b9d2-25af7330a6fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51ca6b3a-27d8-4621-9a17-9dcca312d778",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Pick one message to explain\n",
    "i = 0  # Change this to see different messages\n",
    "\n",
    "row = X_train_tfidf[i].toarray()[0]\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Get non-zero TF-IDF scores\n",
    "nonzero_words = [(feature_names[j], row[j]) for j in row.nonzero()[0]]\n",
    "\n",
    "# Sort by score\n",
    "df_words = pd.DataFrame(nonzero_words, columns=[\"word\", \"tfidf_score\"]).sort_values(by=\"tfidf_score\", ascending=False)\n",
    "\n",
    "df_words.head(10)  # Top 10 important words for message i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4c7ce05-7944-4c39-ad7c-4572fee59208",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_words.head(10).plot.bar(x='word', y='tfidf_score', title='Top Words in Message', legend=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "57569ab0-f881-40f5-af32-6e95d725c500",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\"TF-IDF helps the model ignore common words like 'the', 'is', 'you', and instead focus on words that stand out. For example, the word 'free' appears in many spam messages but not in most normal messages — so it gets a high score.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d9da4b4f-4489-4524-8a34-96a89cbeed00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "047f3530-a64b-4f71-b70c-fc19a9148cde",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_tfidf, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee1b583f-e7ae-4197-8582-99db3c6ecac0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "We use Logistic Regression, a simple and effective classification model.\n",
    "\n",
    "It learns patterns in word usage that separate \"spam\" from \"ham\".\n",
    "\n",
    "Despite the name, logistic regression is a classification algorithm — not regression!\n",
    "\n",
    "It works like this:\n",
    "It finds a boundary line (or surface) that best separates the two classes.\n",
    "\n",
    "The model learns weights for each word (feature) during training.\n",
    "\n",
    "It uses the logistic (sigmoid) function to estimate the probability that a message is spam.\n",
    "\n",
    "Imagine every word in a message votes whether it thinks the message is spam or not:\n",
    "\n",
    "Some words like “Congratulations”, “Free”, “Win” vote more heavily toward spam.\n",
    "\n",
    "Words like “Lunch”, “Meeting”, or “Hey” lean toward ham.\n",
    "\n",
    "The model adds up the weighted votes, and if the final score crosses a threshold (usually 0.5), it calls the message spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce7b78bd-da37-4e21-8427-2d3a6cd0e372",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99ef89ec-63d4-4397-9897-431409b928a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This gives precision, recall, and F1-score.\n",
    "\n",
    "Pay attention to how well it performs on both \"spam\" and \"ham\".\n",
    "\n",
    "With balanced training data, you’ll likely see:\n",
    "\n",
    "Higher recall for spam\n",
    "\n",
    "More balanced F1-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3c3c765-c384-4a9a-8562-6d5f9c8660e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sample = [\"Congratulations! You won a free ticket to Bahamas!\",\n",
    "          \"click this link\",\n",
    "          \"review the contract - thomas@thomas\",\n",
    "          \"review the contract and click the link thomas@thomas@thomas\"]\n",
    "\n",
    "sample_tfidf = vectorizer.transform(sample)\n",
    "print(clf.predict(sample_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0fadd3fe-3a56-4664-b725-b18db1847302",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pred_proba = clf.predict_proba(sample_tfidf)\n",
    "for msg, prob in zip(sample, pred_proba):\n",
    "    print(f\"{msg} => Spam probability: {prob[1]:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "level 05 - Spam or Not Spam Explained",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
