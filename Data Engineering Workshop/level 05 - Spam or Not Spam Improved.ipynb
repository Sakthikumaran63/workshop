{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15c5d28e-8a59-4357-8cbe-334381189235",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    " https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97fad78b-bd57-43d7-a0c6-75beedbabce1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "filepath = '/Volumes/workspace/sample_schema/sample_volume/SMSSpamCollection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e22f287b-6f3a-4acf-92ed-383d8516ad6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.text(filepath)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e74600d1-f46d-4e03-a4b8-8c56e979bfcb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read the text file into Spark and convert to Pandas\n",
    "df = spark.read.text(filepath)\n",
    "pdf = df.toPandas()\n",
    "\n",
    "# Split label and message\n",
    "pdf[['label', 'message']] = pdf['value'].str.split('\\t', expand=True)\n",
    "pdf = pdf.drop(columns='value')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36d06e54-4ee8-4144-897b-0922976a4911",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Separate ham and spam\n",
    "spam_df = pdf[pdf['label'] == 'spam']\n",
    "ham_df = pdf[pdf['label'] == 'ham']\n",
    "\n",
    "# Step 2: Upsample spam to match ham\n",
    "spam_upsampled = resample(spam_df,\n",
    "                          replace=True,\n",
    "                          n_samples=len(ham_df),\n",
    "                          random_state=42)\n",
    "\n",
    "# Step 3: Combine into a balanced dataset\n",
    "balanced_df = pd.concat([ham_df, spam_upsampled])\n",
    "\n",
    "# Step 4: Train-test split (after balancing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    balanced_df['message'], balanced_df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 5: TF-IDF and model training\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Step 6: Evaluation\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bac83b6-8bf7-43a2-a9a8-51d0ee668e46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sample = [\"Congratulations! You won a free ticket to Bahamas!\",\n",
    "          \"click this link\",\n",
    "          \"review the contract - thomas@thomas\",\n",
    "          \"review the contract and click the link thomas@thomas@thomas\"]\n",
    "\n",
    "sample_tfidf = vectorizer.transform(sample)\n",
    "print(clf.predict(sample_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0fadd3fe-3a56-4664-b725-b18db1847302",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pred_proba = clf.predict_proba(sample_tfidf)\n",
    "for msg, prob in zip(sample, pred_proba):\n",
    "    print(f\"{msg} => Spam probability: {prob[1]:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "level 05 - Spam or Not Spam Improved",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
